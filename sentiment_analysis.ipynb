{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import evaluate\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "file_path_1 = os.getenv(\"DATASET_PATH_1\")\n",
    "file_path_2 = os.getenv(\"DATASET_PATH_2\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 =  pd.read_cs(file_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"text\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10277</th>\n",
       "      <td>Cheap doesn't mean better btw! . . techsall.co...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10278</th>\n",
       "      <td>Nvidia doesn’t want to give up its 2017 ‘crypt...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10279</th>\n",
       "      <td>Nvidia really delayed the 3070 2 weeks .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10280</th>\n",
       "      <td>Let no elim go unnoticed. . . . NVIDIA Highlig...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10281</th>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  Label\n",
       "0                  What a great day!!! Looks like dream.  positive      2\n",
       "1         I feel sorry, I miss you here in the sea beach  positive      2\n",
       "2                                         Don't angry me  negative      0\n",
       "3      We attend in the class just for listening teac...  negative      0\n",
       "4                      Those who want to go, let them go  negative      0\n",
       "...                                                  ...       ...    ...\n",
       "10277  Cheap doesn't mean better btw! . . techsall.co...  negative      0\n",
       "10278  Nvidia doesn’t want to give up its 2017 ‘crypt...   neutral      1\n",
       "10279          Nvidia really delayed the 3070 2 weeks .   negative      0\n",
       "10280  Let no elim go unnoticed. . . . NVIDIA Highlig...  positive      2\n",
       "10281  Just realized the windows partition of my Mac ...  positive      2\n",
       "\n",
       "[10781 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data[\"Label\"] = label_encoder.fit_transform(data[\"sentiment\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer from the correct path\n",
    "model = BertForSequenceClassification.from_pretrained(\"./saved_bert_model\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./saved_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(data[['text','Label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tokens(examples):\n",
    "    return tokenizer(examples[\"text\"], padding= \"max_length\", truncation= True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10781/10781 [00:03<00:00, 3211.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_tokens, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.rename_column(\"Label\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"./results\",\n",
    "    evaluation_strategy= \"epoch\",\n",
    "    save_strategy= \"epoch\",\n",
    "    num_train_epochs= 10,\n",
    "    learning_rate= 2e-5,\n",
    "    weight_decay= 0.01,\n",
    "    logging_dir= \"./logs\",\n",
    "    logging_steps= 10,\n",
    "    logging_strategy= \"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args= training_args,\n",
    "    train_dataset= tokenized_dataset[\"train\"],\n",
    "    eval_dataset= tokenized_dataset[\"test\"],\n",
    "    compute_metrics= compute_metrics,\n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10780' max='10780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10780/10780 55:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.773000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.528600</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10780, training_loss=0.22676840624694258, metrics={'train_runtime': 3317.8408, 'train_samples_per_second': 25.993, 'train_steps_per_second': 3.249, 'total_flos': 5672725286215680.0, 'train_loss': 0.22676840624694258, 'epoch': 10.0})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 17.4029, 'eval_samples_per_second': 123.945, 'eval_steps_per_second': 15.515, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text - I like you and the emotion is ['positive']\n"
     ]
    }
   ],
   "source": [
    "texts = [\"I like you\"]\n",
    "device = next(model.parameters()).device  \n",
    "inputs = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "print(f'the text - {texts[0]} and the emotion is {label_encoder.inverse_transform([preds.cpu().numpy()[0]])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 03:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 16.6695, 'eval_samples_per_second': 129.398, 'eval_steps_per_second': 16.197, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3420023918151855, 'eval_model_preparation_time': 0.0029, 'eval_accuracy': 0.71256374594344, 'eval_runtime': 16.6666, 'eval_samples_per_second': 129.42, 'eval_steps_per_second': 16.2}\n",
      "Test Accuracy: 0.7126\n"
     ]
    }
   ],
   "source": [
    "test_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(test_results)  # Confirm if \"eval_accuracy\" is now present\n",
    "print(f\"Test Accuracy: {test_results['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "model_name = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "\n",
    "    tokenized_text = roberta_tokenizer(text, return_tensors= 'pt')\n",
    "    output = roberta_model(**tokenized_text)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    scores_dict = {0 : \"Negative\",1:  \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "    sentiment = scores_dict[np.argmax(scores)]\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10781/10781 [00:02<00:00, 4340.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_tokens, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tokenized_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 8624\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2157\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.rename_column(\"Label\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2157/2157 [02:36<00:00, 13.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(example):\n",
    "    example['sentiment'] = classify(example['text'])\n",
    "\n",
    "    return example\n",
    "\n",
    "predictions = test_set.map(make_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6657394529439036"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "y_true = [label_map[label] for label in predictions['Label']]\n",
    "y_pred = predictions['sentiment']\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
